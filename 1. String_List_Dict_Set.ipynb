{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Reading a file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number lines 2618\n",
      "total number of words 17121\n",
      "Total Number of Unique words  3478\n"
     ]
    }
   ],
   "source": [
    "import string \n",
    "\n",
    "file_name = \"sonnets.txt\"\n",
    "\n",
    "# open file in read mode \n",
    "file = open(file_name, \"r\")\n",
    "\n",
    "# read the lines \n",
    "lines = file.readlines()\n",
    "\n",
    "#Total Number of Lines \n",
    "total_lines = len(lines)\n",
    "print(\"Total Number lines\", total_lines)\n",
    "\n",
    "# extract words from lines \n",
    "words_list =[]\n",
    "for line in lines:\n",
    "    line_words = line.replace(\"-\", \" \").strip().split()\n",
    "    \n",
    "    # its empty line \n",
    "    if len(line_words)<=1:\n",
    "        continue \n",
    "        \n",
    "    for word in line_words:\n",
    "        if word and len(word)>1:\n",
    "            words_list.append(word.strip(string.punctuation))\n",
    "\n",
    "# total number of words \n",
    "print(\"total number of words\", len(words_list))\n",
    "\n",
    "unique_words = set(words_list)\n",
    "# total number of unique words \n",
    "print(\"Total Number of Unique words \", len(unique_words))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. check which letter is not repeated in the unique word list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a is not repeated\n",
      "h is not repeated\n",
      "i is not repeated\n",
      "j is not repeated\n",
      "k is not repeated\n",
      "q is not repeated\n",
      "u is not repeated\n",
      "v is not repeated\n",
      "w is not repeated\n",
      "x is not repeated\n",
      "y is not repeated\n",
      "z is not repeated\n"
     ]
    }
   ],
   "source": [
    "for letter in string.ascii_lowercase:\n",
    "    for word in unique_words:\n",
    "        exists = False \n",
    "        if letter*2 in word:\n",
    "            exists = True\n",
    "            break\n",
    "    if not exists:\n",
    "        print(letter,\"is not repeated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. words containing cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuse\n",
      "acceptable\n",
      "accusing\n",
      "accident\n",
      "accidents\n",
      "succeeding\n",
      "accuse\n",
      "accumulate\n",
      "succession\n",
      "accessary\n",
      "account\n",
      "accents\n",
      "acceptance\n",
      "successive\n"
     ]
    }
   ],
   "source": [
    "for word in unique_words:\n",
    "    if \"cc\" in word:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Palidromes in entire word list  --> approach 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      "sees\n",
      "noon\n",
      "eye\n",
      "peep\n",
      "ere\n",
      "O\n",
      "did\n",
      "level\n"
     ]
    }
   ],
   "source": [
    "# loop through each word \n",
    "for word in unique_words:\n",
    "    palindrome = False\n",
    "    for index in range(len(word)):\n",
    "        if word[index]!= word[-(index+1)]:\n",
    "            palindrome = True\n",
    "            break; \n",
    "    if not palindrome:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.Palidromes in entire word list --> approach 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      "sees\n",
      "noon\n",
      "eye\n",
      "peep\n",
      "ere\n",
      "O\n",
      "did\n",
      "level\n"
     ]
    }
   ],
   "source": [
    "# loop through each word \n",
    "for word in unique_words:\n",
    "    if word == word[::-1]:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Finding longest palindrome "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longest Palindrome is  level\n"
     ]
    }
   ],
   "source": [
    "longest_palindrome = \"\"\n",
    "# loop through each word \n",
    "for word in unique_words:\n",
    "    if word == word[::-1]:\n",
    "        if len(word) > len(longest_palindrome):\n",
    "            longest_palindrome = word\n",
    "print(\"longest Palindrome is \", longest_palindrome)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Time consumption of search in list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of scrabble words 267751\n",
      "3478\n",
      "14.070455074310303\n"
     ]
    }
   ],
   "source": [
    "# read Scrabble Words files and store them in scrab_words\n",
    "scrab_file = \"sowpods.txt\"\n",
    "scrab_words = [word.strip()  for word in open(scrab_file, \"r\").readlines()]\n",
    "print(\"total number of scrabble words\" , len(scrab_words))\n",
    "\n",
    "import time \n",
    "start = time.time()\n",
    "# Total number of words present in unique_words but not in scrab_words\n",
    "counter = 0\n",
    "for word in unique_words:\n",
    "    if not word in scrab_words:\n",
    "        counter +=1\n",
    "\n",
    "end = time.time()\n",
    "print(counter)\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Time consumption of search in dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3478\n",
      "0.0014510154724121094\n"
     ]
    }
   ],
   "source": [
    "# convert above scrabble word list into dictionary \n",
    "scrab_dict = dict((elt,1)for elt in scrab_words)\n",
    "\n",
    "import time \n",
    "start = time.time()\n",
    "# Total number of words present in unique_words but not in scrab_words\n",
    "counter = 0\n",
    "for word in unique_words:\n",
    "    if not word in scrab_dict:\n",
    "        counter +=1\n",
    "\n",
    "end = time.time()\n",
    "print(counter)\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Time consumption of search in set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3478\n",
      "0.0059719085693359375\n"
     ]
    }
   ],
   "source": [
    "# convert above scrabble word list into set\n",
    "scrab_set = set(scrab_words)\n",
    "\n",
    "import time \n",
    "start = time.time()\n",
    "# Total number of words present in unique_words but not in scrab_words\n",
    "counter = 0\n",
    "for word in unique_words:\n",
    "    if not word in scrab_set:\n",
    "        counter +=1\n",
    "\n",
    "end = time.time()\n",
    "print(counter)\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note:  set datastructure also similar searching mechanisam as dict but sets do not force us to have key , value pair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. List comprehensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n"
     ]
    }
   ],
   "source": [
    "# list comprehensions basic example \n",
    "# square of number till 10\n",
    "list_word = [e**2 for e in range(11)]\n",
    "print(list_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AA',\n",
       " 'ABA',\n",
       " 'ABBA',\n",
       " 'ACCA',\n",
       " 'AGA',\n",
       " 'AHA',\n",
       " 'AIA',\n",
       " 'AKA',\n",
       " 'ALA',\n",
       " 'ALULA',\n",
       " 'AMA',\n",
       " 'ANA',\n",
       " 'ANANA',\n",
       " 'ANNA',\n",
       " 'ARAARA',\n",
       " 'ATAATA',\n",
       " 'AUA',\n",
       " 'AVA',\n",
       " 'AWA',\n",
       " 'BIB',\n",
       " 'BOB',\n",
       " 'BOOB',\n",
       " 'BUB',\n",
       " 'CIVIC',\n",
       " 'DAD',\n",
       " 'DEED',\n",
       " 'DEGGED',\n",
       " 'DEIFIED',\n",
       " 'DEKED',\n",
       " 'DELED',\n",
       " 'DENNED',\n",
       " 'DERED',\n",
       " 'DEWED',\n",
       " 'DID',\n",
       " 'DOD',\n",
       " 'DUD',\n",
       " 'ECCE',\n",
       " 'EE',\n",
       " 'EKE',\n",
       " 'EME',\n",
       " 'ENE',\n",
       " 'ERE',\n",
       " 'ESSE',\n",
       " 'EVE',\n",
       " 'EWE',\n",
       " 'EYE',\n",
       " 'GAG',\n",
       " 'GIG',\n",
       " 'GOOG',\n",
       " 'HADEDAH',\n",
       " 'HAH',\n",
       " 'HAJJAH',\n",
       " 'HALALAH',\n",
       " 'HALLAH',\n",
       " 'HEH',\n",
       " 'HOH',\n",
       " 'HUH',\n",
       " 'IWI',\n",
       " 'KAIAK',\n",
       " 'KAK',\n",
       " 'KAYAK',\n",
       " 'KEEK',\n",
       " 'KOOK',\n",
       " 'LEMEL',\n",
       " 'LEVEL',\n",
       " 'MADAM',\n",
       " 'MALAM',\n",
       " 'MALLAM',\n",
       " 'MAM',\n",
       " 'MARRAM',\n",
       " 'MEM',\n",
       " 'MIM',\n",
       " 'MINIM',\n",
       " 'MM',\n",
       " 'MOM',\n",
       " 'MUM',\n",
       " 'NAAN',\n",
       " 'NAN',\n",
       " 'NON',\n",
       " 'NOON',\n",
       " 'NUN',\n",
       " 'OBO',\n",
       " 'OHO',\n",
       " 'ONO',\n",
       " 'OO',\n",
       " 'OPPO',\n",
       " 'OTTO',\n",
       " 'OXO',\n",
       " 'PAP',\n",
       " 'PEEP',\n",
       " 'PEP',\n",
       " 'PIP',\n",
       " 'POOP',\n",
       " 'POP',\n",
       " 'PULLUP',\n",
       " 'PUP',\n",
       " 'RADAR',\n",
       " 'REDDER',\n",
       " 'REFER',\n",
       " 'REIFIER',\n",
       " 'REPAPER',\n",
       " 'REVIVER',\n",
       " 'ROTATOR',\n",
       " 'ROTAVATOR',\n",
       " 'ROTOR',\n",
       " 'SAGAS',\n",
       " 'SAMAS',\n",
       " 'SEDES',\n",
       " 'SEES',\n",
       " 'SEITIES',\n",
       " 'SELES',\n",
       " 'SELLES',\n",
       " 'SEMEMES',\n",
       " 'SEMES',\n",
       " 'SERES',\n",
       " 'SERRES',\n",
       " 'SESSES',\n",
       " 'SEXES',\n",
       " 'SHAHS',\n",
       " 'SIMIS',\n",
       " 'SIRIS',\n",
       " 'SIS',\n",
       " 'SOLOS',\n",
       " 'SOS',\n",
       " 'STATS',\n",
       " 'STETS',\n",
       " 'STOTS',\n",
       " 'SUCCUS',\n",
       " 'SULUS',\n",
       " 'SUS',\n",
       " 'SUSUS',\n",
       " 'TALLAT',\n",
       " 'TAT',\n",
       " 'TENET',\n",
       " 'TERRET',\n",
       " 'TET',\n",
       " 'TIRRIT',\n",
       " 'TIT',\n",
       " 'TOOT',\n",
       " 'TOROT',\n",
       " 'TOT',\n",
       " 'TUT',\n",
       " 'ULU',\n",
       " 'UMU',\n",
       " 'UTU',\n",
       " 'VAV',\n",
       " 'WAW',\n",
       " 'WOW',\n",
       " 'YAY',\n",
       " 'ZIZ',\n",
       " 'ZUZ',\n",
       " 'ZZZ']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all the palindromes in scrab_words\n",
    "[word for word in scrab_words if word == word[::-1]]\n",
    "\n",
    "# list comprehensions are compact of creating lists from another list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
